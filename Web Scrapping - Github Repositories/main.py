# -*- coding: utf-8 -*-
"""project1_web_scrapping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V5ZcBwl2_khgSLfelifKBOhQr5kFxxsJ
"""

import pandas as pd

from bs4 import BeautifulSoup

import requests

url = 'https://github.com/collections'
uri = 'https://github.com'

response=requests.get(url)
##response.status_code
html_response = response.text

doc= BeautifulSoup(html_response,"html.parser")

collection = doc.find_all('div',class_='col-10 col-md-11')
col_link = []
for col in collection:
  col_link.append(uri+col.find('a')["href"])
print(col_link)

result_dict ={
    "collection_name":[],
    "repository_name":[],
    "repository_user":[],
    "repository_link":[],
    "no_of_stars":[],
    "no_of_forks":[],
    "programming_lang":[],
    "repository_desc":[]}


def data_from_col(url_link):
    res = requests.get(url_link)
    htmlres = res.text
    #print(len(htmlres))
    doc1=BeautifulSoup(htmlres,"html.parser")
    title = doc1.find('h1', class_='h1 lh-condensed mb-3').text
    count = 0
    #repos = doc1.find_all('h1',class_='h3 lh-condensed')
    repos = doc1.find_all('article')

    for repo in repos:
        if repo.find("div",class_='h6 color-fg-muted text-uppercase mb-1') is None : # to avoid videos posted under collections
            string = repo.find('a').text.strip().split('\n')
            result_dict["collection_name"].append(title)
            repo_name = string[0][0:string[0].find(" ")]
            result_dict["repository_name"].append(repo_name)
            repo_user =  string[1].strip()
            result_dict["repository_user"].append(repo_user)
            repo_link=uri+'/'+repo_name +'/'+repo_user
            result_dict["repository_link"].append(repo_link)
            if(repo.find('div',class_="color-fg-muted mb-2 ws-normal") is None) :
              desc = "No Description"
            else:
              desc = repo.find('div',class_="color-fg-muted mb-2 ws-normal").text
            result_dict["repository_desc"].append(desc)
            svgs = repo.find_all('a',class_='d-inline-block Link--secondary mr-4')
            stars = int(svgs[0].text)
            forks = int(svgs[1].text)
            if(repo.find('span', itemprop = 'programmingLanguage') is None):
              language = "not specified"
            else :
              language = repo.find('span', itemprop = 'programmingLanguage').text
            result_dict["no_of_stars"].append(stars)
            result_dict["no_of_forks"].append(forks)
            result_dict["programming_lang"].append(language)
            count = count+1



for i in col_link:
    data_from_col(i)
#print(result_dict)

# csv format plan:
# 1. collection name
# 2. user name
# 3. repo name
# 4. stars
# 5. forks
# 6. language
# 7. repo link
# 8. repo description

df = pd.DataFrame(result_dict)
df.to_csv("result.csv")